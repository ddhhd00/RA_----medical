{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "ONQkiSmNcmXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKXI8xG2ckKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv('gastric_cancer_data.csv')\n",
        "\n",
        "# 데이터 탐색\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# 결측치 처리: 평균으로 대체\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(data)\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data = pd.DataFrame(data_imputed, columns=data.columns)\n",
        "\n",
        "# 특성과 라벨 분리\n",
        "X = data.drop('target', axis=1)  # 'target'은 위암 발생 여부\n",
        "y = data['target']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"훈련 데이터 크기:\", X_train.shape)\n",
        "print(\"테스트 데이터 크기:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv('gastric_cancer_data.csv')\n",
        "\n",
        "# 데이터 탐색\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data.describe())\n",
        "\n",
        "# 결측치 처리: 수치형 변수는 평균으로, 범주형 변수는 최빈값으로 대체\n",
        "num_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_features = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 수치형 변수 전처리\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 범주형 변수 전처리\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# 전체 전처리 파이프라인\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_transformer, num_features),\n",
        "        ('cat', cat_transformer, cat_features)\n",
        "    ])\n",
        "\n",
        "# 데이터 전처리\n",
        "X = data.drop('target', axis=1)  # 'target'은 위암 발생 여부\n",
        "y = data['target']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 전처리 적용\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"훈련 데이터 크기:\", X_train.shape)\n",
        "print(\"테스트 데이터 크기:\", X_test.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fv-vvGpYdH6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델"
      ],
      "metadata": {
        "id": "nWPHHlOVcqbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 모델 정의\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 하이퍼파라미터 튜닝을 위한 그리드 서치\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "7TwG64IXctye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습"
      ],
      "metadata": {
        "id": "ryRyR0orc6xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 학습 과정 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='훈련 정확도')\n",
        "plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "plt.title('정확도 변화')\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('정확도')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='훈련 손실')\n",
        "plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "plt.title('손실 변화')\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('손실')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "61HXF4iEc7hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망"
      ],
      "metadata": {
        "id": "ONZ1pfxMc3MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 모델 정의\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # 이진 분류\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "zccoO0FOc43-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 모델 정의\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # 이진 분류\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "c2ksYR2vdSmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습 및 평가"
      ],
      "metadata": {
        "id": "tzw6WMeecwJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 모델 학습\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"정확도:\", accuracy)\n",
        "print(\"혼동 행렬:\\n\", conf_matrix)\n",
        "print(\"분류 보고서:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "D7mNxxwPcxeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 중요도 분석을 위한 SHAP 값 계산\n",
        "import shap\n",
        "\n",
        "# SHAP 값 계산\n",
        "explainer = shap.KernelExplainer(model.predict, X_train)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# SHAP 값 시각화\n",
        "shap.summary_plot(shap_values, X_test, feature_names=data.drop('target', axis=1).columns)\n"
      ],
      "metadata": {
        "id": "Vj0RViVYdWEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 중요 특성 시각화\n",
        "feature_importances = best_model.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "# 중요도 데이터프레임 생성\n",
        "importance_df = pd.DataFrame({'특성': features, '중요도': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='중요도', ascending=False)\n",
        "\n",
        "# 중요 특성 바 차트\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='중요도', y='특성', data=importance_df)\n",
        "plt.title('특성 중요도')\n",
        "plt.show()\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['음성', '양성'], yticklabels=['음성', '양성'])\n",
        "plt.ylabel('실제값')\n",
        "plt.xlabel('예측값')\n",
        "plt.title('혼동 행렬')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "58i8I6NzcyfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 최적화"
      ],
      "metadata": {
        "id": "CuFTDiNndXGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 하이퍼파라미터 튜닝을 위한 GridSearchCV 설정\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# RandomForestClassifier 예시\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
        "\n",
        "# 최적 모델 평가\n",
        "best_rf_y_pred = best_rf_model.predict(X_test)\n",
        "best_rf_conf_matrix = confusion_matrix(y_test, best_rf_y_pred)\n",
        "print(\"최적 Random Forest 혼동 행렬:\\n\", best_rf_conf_matrix)\n"
      ],
      "metadata": {
        "id": "umHWoSz0dX7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결론"
      ],
      "metadata": {
        "id": "b_BYjpVMdY8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결론\n",
        "- 위암 발생 예측 모델을 구축하기 위해 심층 신경망과 랜덤 포레스트 모델을 사용하여 성능을 평가했습니다.\n",
        "- 두 모델 모두 양호한 성능을 보였으며, 향후 연구에서는 데이터 증강 및 추가적인 특성 엔지니어링을 통해 모델 성능을 개선할 수 있습니다.\n",
        "\n",
        "# 향후 연구 방향\n",
        "1. **데이터 증강**: 더 많은 데이터를 수집하거나 기존 데이터를 변형하여 모델의 일반화 능력을 향상시킬 수 있습니다.\n",
        "2. **다양한 모델 시도**: XGBoost, LightGBM과 같은 다른 머신러닝 알고리즘을 적용해 볼 수 있습니다.\n",
        "3. **특성 엔지니어링**: 도메인 지식을 바탕으로 새로운 특성을 생성하여 모델 성능을 향상시킬 수 있습니다.\n",
        "4. **해석 가능성**: SHAP 및 LIME과 같은 기법을 통해 모델의 예측 결과를 해석하고, 의사결정에 활용할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "4_TAzb64daZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}